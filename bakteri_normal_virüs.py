# -*- coding: utf-8 -*-
"""Bakteri Normal Vir√ºs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16aWIhgXQGiy7dQNsYVhXAwl9D1U8yTG_
"""

import numpy as np
import os
import random
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Flatten
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Conv2D, MaxPooling2D,ZeroPadding2D
alexnet=Sequential()
alexnet.add(Conv2D(96,kernel_size=(11,11),strides=(4,4),activation='relu', input_shape=(227,227,3)))
alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
alexnet.add(ZeroPadding2D((2,2)))
alexnet.add(Conv2D(256,kernel_size=(5,5),activation='relu',strides=(1,1
)))
alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
alexnet.add(ZeroPadding2D((1,1)))
alexnet.add(Conv2D(384,kernel_size=(3,3),activation='relu'))
alexnet.add(ZeroPadding2D((1,1)))
alexnet.add(Conv2D(384,kernel_size=(3,3),activation='relu'))
alexnet.add(ZeroPadding2D((1,1)))
alexnet.add(Conv2D(256,kernel_size=(3,3),activation='relu'))
alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
alexnet.add(Flatten())
alexnet.add(Dense(512,activation='relu'))
alexnet.add(Dense(512,activation='relu'))
alexnet.add(Dense(3,activation='softmax'))
alexnet.compile(loss='categorical_crossentropy',optimizer='sgd',metrics
=["accuracy"])
alexnet.summary()

from google.colab import drive
drive.mount("/content/drive")
trainPath='./drive/MyDrive/chest_xray/train/'
testPath='./drive/MyDrive/chest_xray/test/'

trainDataGen=ImageDataGenerator(
rescale=1./255,
validation_split=0.1
)

testDataGen=ImageDataGenerator(
rescale=1./255

)

trainGen=trainDataGen.flow_from_directory(
trainPath,
target_size=(227,227),
color_mode='rgb',
class_mode='categorical',
batch_size=32,
subset='training'
)
valGen=trainDataGen.flow_from_directory(
trainPath,
target_size=(227,227),
color_mode='rgb',
class_mode='categorical',
batch_size=32,
subset='validation'
)#

testGen=testDataGen.flow_from_directory(
testPath,
target_size=(227,227),
color_mode='rgb',
class_mode='categorical',
batch_size=32
)

history=alexnet.fit(
trainGen,
steps_per_epoch=trainGen.samples//32,
validation_data=valGen,
epochs=10,
validation_steps=testGen.samples//32
)
plt.figure(figsize=(10,10))
plt.subplot(211)
plt.title("Accuracy")
plt.plot(history.history["accuracy"],color='r',label='train')
plt.plot(history.history["val_accuracy"],color='b',label='validation')
plt.legend(loc='best')
plt.subplot(212)
plt.title("Loss")
plt.plot(history.history["loss"],color='r',label='train')

plt.plot(history.history["val_loss"],color='b',label='validation')
plt.legend(loc='best')
plt.tight_layout()
plt.show()
import numpy as np
tahminler = alexnet.predict(testGen, steps=testGen.samples//1)
tahmin_siniflari = np.argmax(tahminler, axis=1)
gercek_Deger= testGen.classes

from sklearn.metrics import confusion_matrix, classification_report
print('Confusion Matrix')
cm=confusion_matrix(gercek_Deger,tahmin_siniflari )
print(cm,"\n")
acc=(cm[0][0]+cm[1][1])/len(valGen)
print("Acc:",acc)
sen=cm[0][0]/(cm[0][0]+cm[1][0])
print("Sen:",sen)
pre=cm[0][0]/(cm[0][0]+cm[0][1])
print("Pre:",pre)
f1=2*((pre*sen)/(pre+sen))
print("F1:",f1)